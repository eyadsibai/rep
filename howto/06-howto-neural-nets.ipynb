{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About \n",
    "\n",
    "This notebook demonstrates neural networks (NN) classifiers, which are provided by __Reproducible experiment platform (REP)__ package. <br /> REP contains wrappers for following NN libraries:\n",
    "* __theanets__\n",
    "* __neurolab__ \n",
    "* __pybrain__ \n",
    "\n",
    "\n",
    "### In this notebook we show: \n",
    "* train classifier\n",
    "* get predictions \n",
    "* measure quality\n",
    "* pretraining and partial fitting\n",
    "* combine classifiers using meta-algorithms\n",
    "\n",
    "Most of this is done in the same way as for other classifiers (see notebook [01-howto-Classifiers.ipynb](https://github.com/yandex/rep/blob/master/howto/01-howto-Classifiers.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy, pandas\n",
    "from rep.utils import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sig_data = pandas.read_csv('toy_datasets/toyMC_sig_mass.csv', sep='\\t')\n",
    "bck_data = pandas.read_csv('toy_datasets/toyMC_bck_mass.csv', sep='\\t')\n",
    "\n",
    "labels = numpy.array([1] * len(sig_data) + [0] * len(bck_data))\n",
    "data = pandas.concat([sig_data, bck_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First rows of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDF1</th>\n",
       "      <th>CDF2</th>\n",
       "      <th>CDF3</th>\n",
       "      <th>DOCAone</th>\n",
       "      <th>DOCAthree</th>\n",
       "      <th>DOCAtwo</th>\n",
       "      <th>FlightDistance</th>\n",
       "      <th>FlightDistanceError</th>\n",
       "      <th>Hlt1Dec</th>\n",
       "      <th>Hlt2Dec</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_IP</th>\n",
       "      <th>p1_IPSig</th>\n",
       "      <th>p1_Laura_IsoBDT</th>\n",
       "      <th>p1_pt</th>\n",
       "      <th>p2_IP</th>\n",
       "      <th>p2_IPSig</th>\n",
       "      <th>p2_Laura_IsoBDT</th>\n",
       "      <th>p2_pt</th>\n",
       "      <th>peakingbkg</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.111337</td>\n",
       "      <td> 0.012695</td>\n",
       "      <td> 0.123426</td>\n",
       "      <td> 162.650955</td>\n",
       "      <td> 0.870942</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 11.314665</td>\n",
       "      <td> 83.196968</td>\n",
       "      <td>-0.223668</td>\n",
       "      <td> 699.066467</td>\n",
       "      <td> 9.799975</td>\n",
       "      <td> 64.790207</td>\n",
       "      <td>-0.121159</td>\n",
       "      <td> 521.628174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  220.742111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.759755</td>\n",
       "      <td> 0.597375</td>\n",
       "      <td> 0.389256</td>\n",
       "      <td> 0.021781</td>\n",
       "      <td> 0.094551</td>\n",
       "      <td> 0.088421</td>\n",
       "      <td>   4.193265</td>\n",
       "      <td> 1.262280</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.720070</td>\n",
       "      <td>  7.237868</td>\n",
       "      <td>-0.256142</td>\n",
       "      <td> 587.628935</td>\n",
       "      <td> 0.882111</td>\n",
       "      <td>  8.834325</td>\n",
       "      <td>-0.203220</td>\n",
       "      <td> 532.679950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  661.208843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.796142</td>\n",
       "      <td> 0.566286</td>\n",
       "      <td> 0.011852</td>\n",
       "      <td> 0.004400</td>\n",
       "      <td> 0.009153</td>\n",
       "      <td>   1.580610</td>\n",
       "      <td> 0.261697</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.362181</td>\n",
       "      <td>  4.173097</td>\n",
       "      <td>-0.252788</td>\n",
       "      <td> 802.746495</td>\n",
       "      <td> 0.427290</td>\n",
       "      <td>  5.008959</td>\n",
       "      <td>-0.409469</td>\n",
       "      <td> 674.122342</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1290.963982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0.716397</td>\n",
       "      <td> 0.524712</td>\n",
       "      <td> 0.279033</td>\n",
       "      <td> 0.015171</td>\n",
       "      <td> 0.083900</td>\n",
       "      <td> 0.069127</td>\n",
       "      <td>   7.884569</td>\n",
       "      <td> 1.310151</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.753449</td>\n",
       "      <td>  6.615949</td>\n",
       "      <td>-0.253550</td>\n",
       "      <td> 564.203857</td>\n",
       "      <td> 0.917409</td>\n",
       "      <td>  8.695459</td>\n",
       "      <td>-0.192284</td>\n",
       "      <td> 537.791687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  692.654175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.996479</td>\n",
       "      <td> 0.888159</td>\n",
       "      <td> 0.005547</td>\n",
       "      <td> 0.070438</td>\n",
       "      <td> 0.064689</td>\n",
       "      <td>  -2.267649</td>\n",
       "      <td> 0.139555</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.589455</td>\n",
       "      <td> 21.869143</td>\n",
       "      <td>-0.254778</td>\n",
       "      <td> 746.624928</td>\n",
       "      <td> 0.388996</td>\n",
       "      <td>  8.465344</td>\n",
       "      <td>-0.217319</td>\n",
       "      <td> 988.539221</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1328.837840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CDF1      CDF2      CDF3   DOCAone  DOCAthree   DOCAtwo  \\\n",
       "0  1.000000  1.000000  1.000000  0.111337   0.012695  0.123426   \n",
       "1  0.759755  0.597375  0.389256  0.021781   0.094551  0.088421   \n",
       "2  1.000000  0.796142  0.566286  0.011852   0.004400  0.009153   \n",
       "3  0.716397  0.524712  0.279033  0.015171   0.083900  0.069127   \n",
       "4  1.000000  0.996479  0.888159  0.005547   0.070438  0.064689   \n",
       "\n",
       "   FlightDistance  FlightDistanceError  Hlt1Dec  Hlt2Dec   ...         p1_IP  \\\n",
       "0      162.650955             0.870942        0        0   ...     11.314665   \n",
       "1        4.193265             1.262280        0        0   ...      0.720070   \n",
       "2        1.580610             0.261697        0        0   ...      0.362181   \n",
       "3        7.884569             1.310151        0        0   ...      0.753449   \n",
       "4       -2.267649             0.139555        0        0   ...      0.589455   \n",
       "\n",
       "    p1_IPSig  p1_Laura_IsoBDT       p1_pt     p2_IP   p2_IPSig  \\\n",
       "0  83.196968        -0.223668  699.066467  9.799975  64.790207   \n",
       "1   7.237868        -0.256142  587.628935  0.882111   8.834325   \n",
       "2   4.173097        -0.252788  802.746495  0.427290   5.008959   \n",
       "3   6.615949        -0.253550  564.203857  0.917409   8.695459   \n",
       "4  21.869143        -0.254778  746.624928  0.388996   8.465344   \n",
       "\n",
       "   p2_Laura_IsoBDT       p2_pt  peakingbkg           pt  \n",
       "0        -0.121159  521.628174         NaN   220.742111  \n",
       "1        -0.203220  532.679950         NaN   661.208843  \n",
       "2        -0.409469  674.122342         NaN  1290.963982  \n",
       "3        -0.192284  537.791687         NaN   692.654175  \n",
       "4        -0.217319  988.539221         NaN  1328.837840  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get train and test data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural nets\n",
    "\n",
    "All nets inherit from __sklearn.BaseEstimator__ and have the same interface as another wrappers in REP (details see in **01-howto-Classifiers**)\n",
    "\n",
    "All of these nets libraries **support**:\n",
    "\n",
    "* classification\n",
    "* multi-classification\n",
    "* regression\n",
    "* multi-target regresssion\n",
    "* additional fitting (using `partial_fit` method)\n",
    "\n",
    "and **don't support**:\n",
    "\n",
    "* staged prediction methoods\n",
    "* weights for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = [\"FlightDistance\", \"FlightDistanceError\", \"IP\", \"VertexChi2\", \n",
    "             \"pt\", \"p0_pt\", \"p1_pt\", \"p2_pt\", 'LifeTime','dira']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier from Theanets library. \n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    :param features: list of features to train model\n",
      "    :type features: None or list(str)\n",
      "    :param layers: a sequence of values specifying the **hidden** layer configuration for the network.\n",
      "        For more information please see 'Specifying layers' in theanets documentation:\n",
      "        http://theanets.readthedocs.org/en/latest/creating.html#creating-specifying-layers\n",
      "        Note that theanets \"layers\" parameter included input and output layers in the sequence as well.\n",
      "    :type layers: sequence of int, tuple, dict\n",
      "    :param int input_layer: size of the input layer. If equals -1, the size is taken from the training dataset\n",
      "    :param int output_layer: size of the output layer. If equals -1, the size is taken from the training dataset\n",
      "    :param str hidden_activation: the name of an activation function to use on hidden network layers by default\n",
      "    :param str output_activation: the name of an activation function to use on the output layer by default\n",
      "    :param float input_noise: standard deviation of desired noise to inject into input\n",
      "    :param float hidden_noise: standard deviation of desired noise to inject into hidden unit activation output\n",
      "    :param input_dropouts: proportion of input units to randomly set to 0\n",
      "    :type input_dropouts: float in [0, 1]\n",
      "    :param hidden_dropouts: proportion of hidden unit activations to randomly set to 0\n",
      "    :type hidden_dropouts: float in [0, 1]\n",
      "    :param decode_from: any of the hidden layers can be tapped at the output. Just specify a value greater than\n",
      "        1 to tap the last N hidden layers. The default is 1, which decodes from just the last layer\n",
      "    :type decode_from: positive int\n",
      "    :param scaler: scaler used to transform data. If False, scaling will not be used\n",
      "    :type scaler: str or sklearn-like transformer or False (do not scale features)\n",
      "    :param trainers: parameters to specify training algorithm(s)\n",
      "        example: [{'optimize': sgd, 'momentum': 0.2}, {'optimize': 'nag'}]\n",
      "    :type trainers: list[dict] or None\n",
      "    :param int random_state: random seed\n",
      "\n",
      "\n",
      "    For more information on available trainers and their parameters, see this page\n",
      "    http://theanets.readthedocs.org/en/latest/training.html\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import TheanetsClassifier\n",
    "print TheanetsClassifier.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '53259' (I am process '54282')\n",
      "WARNING:theano.gof.compilelock:Overriding existing lock by dead process '53259' (I am process '54282')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TheanetsClassifier(decode_from=1,\n",
       "          features=['FlightDistance', 'FlightDistanceError', 'IP', 'VertexChi2', 'pt', 'p0_pt', 'p1_pt', 'p2_pt', 'LifeTime', 'dira'],\n",
       "          hidden_activation='logistic', hidden_dropouts=0, hidden_noise=0,\n",
       "          input_dropouts=0, input_layer=-1, input_noise=0, layers=[20],\n",
       "          output_activation='linear', output_layer=-1, random_state=42,\n",
       "          scaler=StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "          trainers=[{'learning_rate': 0.1, 'optimize': 'nag'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = TheanetsClassifier(features=variables, layers=[20], \n",
    "                        trainers=[{'optimize': 'nag', 'learning_rate': 0.1}])\n",
    "\n",
    "tn.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting probabilities, measuring the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04263913  0.95736087]\n",
      " [ 0.91032442  0.08967558]\n",
      " [ 0.97220917  0.02779083]\n",
      " ..., \n",
      " [ 0.73230451  0.26769549]\n",
      " [ 0.91418271  0.08581729]\n",
      " [ 0.9888496   0.0111504 ]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = tn.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.906091572446\n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theanets multistage training \n",
    "\n",
    "In some cases we need to continue training: i.e., we have new data or current trainer is not efficient anymore.\n",
    "\n",
    "For this purpose there is `partial_fit` method, where you can continue training using different trainer or different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "tn = TheanetsClassifier(features=variables, layers=[10, 10], \n",
    "                        trainers=[{'optimize': 'rprop'}])\n",
    "\n",
    "tn.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  Second stage of fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheanetsClassifier(decode_from=1,\n",
       "          features=['FlightDistance', 'FlightDistanceError', 'IP', 'VertexChi2', 'pt', 'p0_pt', 'p1_pt', 'p2_pt', 'LifeTime', 'dira'],\n",
       "          hidden_activation='logistic', hidden_dropouts=0, hidden_noise=0,\n",
       "          input_dropouts=0, input_layer=-1, input_noise=0, layers=[10, 10],\n",
       "          output_activation='linear', output_layer=-1, random_state=42,\n",
       "          scaler=StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "          trainers=[{'optimize': 'rprop'}, {'optimize': 'adadelta'}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn.partial_fit(train_data, train_labels, **{'optimize': 'adadelta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0256754   0.9743246 ]\n",
      " [ 0.96961642  0.03038358]\n",
      " [ 0.97005419  0.02994581]\n",
      " ..., \n",
      " [ 0.60414954  0.39585046]\n",
      " [ 0.55504215  0.44495785]\n",
      " [ 0.9699952   0.0300048 ]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = tn.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.901973367888\n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier from neurolab library. \n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    :param features: features used in training\n",
      "    :type features: list[str] or None\n",
      "    :param list[int] layers: sequence, number of units inside each **hidden** layer.\n",
      "    :param string net_type: type of network\n",
      "        One of 'feed-forward', 'single-layer', 'competing-layer', 'learning-vector',\n",
      "        'elman-recurrent', 'hopfield-recurrent', 'hemming-recurrent'\n",
      "    :param initf: layer initializers\n",
      "    :type initf: anything implementing call(layer), e.g. nl.init.* or list[nl.init.*] of shape [n_layers]\n",
      "    :param trainf: net train function, default value depends on type of network\n",
      "    :param scaler: transformer to apply to the input objects\n",
      "    :type scaler: str or sklearn-like transformer or False (do not scale features)\n",
      "    :param random_state: ignored, added for uniformity.\n",
      "    :param dict kwargs: additional arguments to net __init__, varies with different net_types\n",
      "\n",
      "    .. seealso:: https://pythonhosted.org/neurolab/lib.html for supported train functions and their parameters.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import NeurolabClassifier\n",
    "print NeurolabClassifier.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train network using Rprop algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ff1922f1af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mneurolab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeurolabClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneurolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_rprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/ipython/rep/rep/estimators/neurolab.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# erasing results of previous training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/ipython/rep/rep/estimators/neurolab.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.98\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/ipython/rep/rep/estimators/neurolab.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y_original, y_train)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/neurolab/core.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/neurolab/core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTrainStop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'show'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/neurolab/train/gd.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input, target)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# regularization grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/neurolab/train/gd.pyc\u001b[0m in \u001b[0;36mcalc\u001b[0;34m(self, net, input, target)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/neurolab/tool.pyc\u001b[0m in \u001b[0;36mff_grad\u001b[0;34m(net, input, target)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mff_grad_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/neurolab/tool.pyc\u001b[0m in \u001b[0;36mff_grad_step\u001b[0;34m(net, out, tar, grad)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mln\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mdS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mdelt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mdelt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 1716\u001b[0;31m                             out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import neurolab\n",
    "nl = NeurolabClassifier(features=variables, layers=[10], epochs=40, trainf=neurolab.train.train_rprop)\n",
    "nl.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training neural network you still can improve it by using partial fit on other data:\n",
    "```\n",
    "nl.partial_fit(new_train_data, new_train_labels)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities and estimate quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict probabilities for each class\n",
    "prob = nl.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict labels\n",
    "nl.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pybrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.estimators import PyBrainClassifier\n",
    "print PyBrainClassifier.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = PyBrainClassifier(features=variables, layers=[10, 2], hiddenclass=['TanhLayer', 'SigmoidLayer'])\n",
    "pb.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities and estimate quality\n",
    "again, we could proceed with training and use new dataset\n",
    "```\n",
    "nl.partial_fit(new_train_data, new_train_labels)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = pb.predict_proba(test_data)\n",
    "print 'ROC AUC:', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling of features\n",
    "initial prescaling of features is frequently crucial to get some appropriate results using neural networks.\n",
    "\n",
    "By default, all the networks use `StandardScaler` from `sklearn`, but you can use any other transformer, say MinMax or self-written by passing appropriate value as scaler. All the networks have same support of `scaler` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# will use StandardScaler\n",
    "NeurolabClassifier(scaler='standard')\n",
    "# will use MinMaxScaler\n",
    "NeurolabClassifier(scaler=MinMaxScaler())\n",
    "# will not use any pretransformation of features\n",
    "NeurolabClassifier(scaler=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages of common interface\n",
    "\n",
    "Let's build an ensemble of neural networks. This will be done by bagging meta-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging over Theanets classifier (same can be done with any neural network)\n",
    "in practice, one will need __many__ networks to get predictions better, then obtained by one network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_tn = TheanetsClassifier(layers=[20], trainers=[{'min_improvement': 0.01}])\n",
    "bagging_tn = BaggingClassifier(base_estimator=base_tn, n_estimators=3)\n",
    "bagging_tn.fit(train_data[variables], train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = bagging_tn.predict_proba(test_data[variables])\n",
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other advantages of common interface\n",
    "There are many things you can do with neural networks now: \n",
    "* cloning\n",
    "* getting / setting parameters as dictionaries \n",
    "* use `grid_search`, play with sizes of hidden layers and other parameters\n",
    "* build pipelines (`sklearn.pipeline`)\n",
    "* use hierarchical training, training on subsets\n",
    "* passing over internet / train classifiers on other machines / distributed learning of ensemles\n",
    "\n",
    "\n",
    "And you can replace classifiers at any moment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
