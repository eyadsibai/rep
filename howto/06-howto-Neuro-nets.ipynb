{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About \n",
    "\n",
    "This notebook demonstrates neuro net classifiers, which are provided by __Reproducible experiment platform (REP)__ package. <br /> REP contains following neuro net libraries:\n",
    "* __theanets__\n",
    "* __neurolab__ \n",
    "* __pybrain__ \n",
    "\n",
    "\n",
    "### In this notebook we show the most simple way to do the same as for rest base wrappers:\n",
    "* train classifier\n",
    "* build predictions \n",
    "* measure quality\n",
    "* combine metaclassifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy, pandas\n",
    "from rep.utils import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sig_data = pandas.read_csv('toy_datasets/toyMC_sig_mass.csv', sep='\\t')\n",
    "bck_data = pandas.read_csv('toy_datasets/toyMC_bck_mass.csv', sep='\\t')\n",
    "\n",
    "labels = numpy.array([1] * len(sig_data) + [0] * len(bck_data))\n",
    "data = pandas.concat([sig_data, bck_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First rows of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDF1</th>\n",
       "      <th>CDF2</th>\n",
       "      <th>CDF3</th>\n",
       "      <th>DOCAone</th>\n",
       "      <th>DOCAthree</th>\n",
       "      <th>DOCAtwo</th>\n",
       "      <th>FlightDistance</th>\n",
       "      <th>FlightDistanceError</th>\n",
       "      <th>Hlt1Dec</th>\n",
       "      <th>Hlt2Dec</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_IP</th>\n",
       "      <th>p1_IPSig</th>\n",
       "      <th>p1_Laura_IsoBDT</th>\n",
       "      <th>p1_pt</th>\n",
       "      <th>p2_IP</th>\n",
       "      <th>p2_IPSig</th>\n",
       "      <th>p2_Laura_IsoBDT</th>\n",
       "      <th>p2_pt</th>\n",
       "      <th>peakingbkg</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.111337</td>\n",
       "      <td> 0.012695</td>\n",
       "      <td> 0.123426</td>\n",
       "      <td> 162.650955</td>\n",
       "      <td> 0.870942</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 11.314665</td>\n",
       "      <td> 83.196968</td>\n",
       "      <td>-0.223668</td>\n",
       "      <td> 699.066467</td>\n",
       "      <td> 9.799975</td>\n",
       "      <td> 64.790207</td>\n",
       "      <td>-0.121159</td>\n",
       "      <td> 521.628174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  220.742111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.759755</td>\n",
       "      <td> 0.597375</td>\n",
       "      <td> 0.389256</td>\n",
       "      <td> 0.021781</td>\n",
       "      <td> 0.094551</td>\n",
       "      <td> 0.088421</td>\n",
       "      <td>   4.193265</td>\n",
       "      <td> 1.262280</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.720070</td>\n",
       "      <td>  7.237868</td>\n",
       "      <td>-0.256142</td>\n",
       "      <td> 587.628935</td>\n",
       "      <td> 0.882111</td>\n",
       "      <td>  8.834325</td>\n",
       "      <td>-0.203220</td>\n",
       "      <td> 532.679950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  661.208843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.796142</td>\n",
       "      <td> 0.566286</td>\n",
       "      <td> 0.011852</td>\n",
       "      <td> 0.004400</td>\n",
       "      <td> 0.009153</td>\n",
       "      <td>   1.580610</td>\n",
       "      <td> 0.261697</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.362181</td>\n",
       "      <td>  4.173097</td>\n",
       "      <td>-0.252788</td>\n",
       "      <td> 802.746495</td>\n",
       "      <td> 0.427290</td>\n",
       "      <td>  5.008959</td>\n",
       "      <td>-0.409469</td>\n",
       "      <td> 674.122342</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1290.963982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0.716397</td>\n",
       "      <td> 0.524712</td>\n",
       "      <td> 0.279033</td>\n",
       "      <td> 0.015171</td>\n",
       "      <td> 0.083900</td>\n",
       "      <td> 0.069127</td>\n",
       "      <td>   7.884569</td>\n",
       "      <td> 1.310151</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.753449</td>\n",
       "      <td>  6.615949</td>\n",
       "      <td>-0.253550</td>\n",
       "      <td> 564.203857</td>\n",
       "      <td> 0.917409</td>\n",
       "      <td>  8.695459</td>\n",
       "      <td>-0.192284</td>\n",
       "      <td> 537.791687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  692.654175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.996479</td>\n",
       "      <td> 0.888159</td>\n",
       "      <td> 0.005547</td>\n",
       "      <td> 0.070438</td>\n",
       "      <td> 0.064689</td>\n",
       "      <td>  -2.267649</td>\n",
       "      <td> 0.139555</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0.589455</td>\n",
       "      <td> 21.869143</td>\n",
       "      <td>-0.254778</td>\n",
       "      <td> 746.624928</td>\n",
       "      <td> 0.388996</td>\n",
       "      <td>  8.465344</td>\n",
       "      <td>-0.217319</td>\n",
       "      <td> 988.539221</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 1328.837840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CDF1      CDF2      CDF3   DOCAone  DOCAthree   DOCAtwo  \\\n",
       "0  1.000000  1.000000  1.000000  0.111337   0.012695  0.123426   \n",
       "1  0.759755  0.597375  0.389256  0.021781   0.094551  0.088421   \n",
       "2  1.000000  0.796142  0.566286  0.011852   0.004400  0.009153   \n",
       "3  0.716397  0.524712  0.279033  0.015171   0.083900  0.069127   \n",
       "4  1.000000  0.996479  0.888159  0.005547   0.070438  0.064689   \n",
       "\n",
       "   FlightDistance  FlightDistanceError  Hlt1Dec  Hlt2Dec   ...         p1_IP  \\\n",
       "0      162.650955             0.870942        0        0   ...     11.314665   \n",
       "1        4.193265             1.262280        0        0   ...      0.720070   \n",
       "2        1.580610             0.261697        0        0   ...      0.362181   \n",
       "3        7.884569             1.310151        0        0   ...      0.753449   \n",
       "4       -2.267649             0.139555        0        0   ...      0.589455   \n",
       "\n",
       "    p1_IPSig  p1_Laura_IsoBDT       p1_pt     p2_IP   p2_IPSig  \\\n",
       "0  83.196968        -0.223668  699.066467  9.799975  64.790207   \n",
       "1   7.237868        -0.256142  587.628935  0.882111   8.834325   \n",
       "2   4.173097        -0.252788  802.746495  0.427290   5.008959   \n",
       "3   6.615949        -0.253550  564.203857  0.917409   8.695459   \n",
       "4  21.869143        -0.254778  746.624928  0.388996   8.465344   \n",
       "\n",
       "   p2_Laura_IsoBDT       p2_pt  peakingbkg           pt  \n",
       "0        -0.121159  521.628174         NaN   220.742111  \n",
       "1        -0.203220  532.679950         NaN   661.208843  \n",
       "2        -0.409469  674.122342         NaN  1290.963982  \n",
       "3        -0.192284  537.791687         NaN   692.654175  \n",
       "4        -0.217319  988.539221         NaN  1328.837840  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get train and test data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural nets\n",
    "\n",
    "All nets inherit from __sklearn.BaseEstimator__ and have the same interface as another wrappers in REP (details see in **01-howto-Classifiers**)\n",
    "\n",
    "All of these nets libraries **support**:\n",
    "\n",
    "* classification\n",
    "* multi-classification\n",
    "* regression\n",
    "* multi-targets regresssion\n",
    "\n",
    "and **don't support**:\n",
    "\n",
    "* staged predict methoods\n",
    "* weights for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = [\"FlightDistance\", \"FlightDistanceError\", \"IP\", \"VertexChi2\", \"pt\", \"p0_pt\", \"p1_pt\", \"p2_pt\", 'LifeTime','dira']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier from Theanets library. \n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    :param features: list of features to train model\n",
      "    :type features: None or list(str)\n",
      "    :param layers: a sequence of values specifying the **hidden** layer configuration for the network.\n",
      "        For more information please see 'Specifying layers' in theanets documentation:\n",
      "        http://theanets.readthedocs.org/en/latest/creating.html#creating-specifying-layers\n",
      "        Note that theanets \"layers\" parameter included input and output layers in the sequence as well.\n",
      "    :type layers: sequence of int, tuple, dict\n",
      "    :param int input_layer: size of the input layer. If equals -1, the size is taken from the training dataset\n",
      "    :param int output_layer: size of the output layer. If equals -1, the size is taken from the training dataset\n",
      "    :param str hidden_activation: the name of an activation function to use on hidden network layers by default\n",
      "    :param str output_activation: the name of an activation function to use on the output layer by default\n",
      "    :param float input_noise: standard deviation of desired noise to inject into input\n",
      "    :param float hidden_noise: standard deviation of desired noise to inject into hidden unit activation output\n",
      "    :param input_dropouts: proportion of input units to randomly set to 0\n",
      "    :type input_dropouts: float in [0, 1]\n",
      "    :param hidden_dropouts: proportion of hidden unit activations to randomly set to 0\n",
      "    :type hidden_dropouts: float in [0, 1]\n",
      "    :param decode_from: any of the hidden layers can be tapped at the output. Just specify a value greater than\n",
      "        1 to tap the last N hidden layers. The default is 1, which decodes from just the last layer\n",
      "    :type decode_from: positive int\n",
      "    :param scaler: scaler used to transform data. If False, scaling will not be used\n",
      "    :type scaler: str or sklearn-like transformer or False (do not scale features)\n",
      "    :param trainers: parameters to specify training algorithm(s)\n",
      "        example: [{'optimize': sgd, 'momentum': 0.2}, {'optimize': 'nag'}]\n",
      "    :type trainers: list[dict] or None\n",
      "    :param int random_state: random seed\n",
      "\n",
      "\n",
      "    For more information on available trainers and their parameters, see this page\n",
      "    http://theanets.readthedocs.org/en/latest/training.html.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import TheanetsClassifier\n",
    "print TheanetsClassifier.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theanets pretraining (unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "tn = TheanetsClassifier(features=variables, layers=[20], \n",
    "                        trainers=[{'optimize': 'pretrain'}])\n",
    "# Unsupervised learning, put any vector with necessary count of classes as y, only numpy.unique(y) will be used \n",
    "tn.fit(train_data, [1] + [0] * (len(train_data) - 1))\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting probabilities, measuring the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30260596  0.69739404]\n",
      " [ 0.30260596  0.69739404]\n",
      " [ 0.14554053  0.85445947]\n",
      " ..., \n",
      " [ 0.18248445  0.81751555]\n",
      " [ 0.30260596  0.69739404]\n",
      " [ 0.17538447  0.82461553]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = tn.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.574939901116\n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Additional fitting using labels for the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheanetsClassifier(decode_from=1,\n",
       "          features=['FlightDistance', 'FlightDistanceError', 'IP', 'VertexChi2', 'pt', 'p0_pt', 'p1_pt', 'p2_pt', 'LifeTime', 'dira'],\n",
       "          hidden_activation='logistic', hidden_dropouts=0, hidden_noise=0,\n",
       "          input_dropouts=0, input_layer=-1, input_noise=0, layers=[20],\n",
       "          output_activation='linear', output_layer=-1, random_state=42,\n",
       "          scaler=StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "          trainers=[{'optimize': 'pretrain'}, {'learning_rate': 0.3, 'optimize': 'nag'}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn.partial_fit(train_data, train_labels, **{'optimize': 'nag', 'learning_rate': 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98404217  0.01595783]\n",
      " [ 0.98306235  0.01693765]\n",
      " [ 0.9243144   0.0756856 ]\n",
      " ..., \n",
      " [ 0.99774784  0.00225216]\n",
      " [ 0.98306233  0.01693767]\n",
      " [ 0.98540877  0.01459123]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = tn.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.905527908521\n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier from neurolab library. \n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    :param tuple[int] layers: sequence of units numbers inside each **hidden** layer.\n",
      "    :param string net_type: type of network\n",
      "        One of 'feed-forward', 'single-layer', 'competing-layer', 'learning-vector',\n",
      "        'elman-recurrent', 'hopfield-recurrent', 'hemming-recurrent'\n",
      "    :param features: features used in training\n",
      "    :type features: list[str] or None\n",
      "    :param initf: layer initializers\n",
      "    :type initf: anything implementing call(layer), e.g. nl.init.* or list[nl.init.*] of shape [n_layers]\n",
      "    :param trainf: net train function, default value depends on type of network\n",
      "    :param scaler: transformer to apply to the input objects\n",
      "    :type scaler: str or sklearn-like transformer or False (do not scale features)\n",
      "    :param list[int] layers: list of numbers denoting size of each hidden layer\n",
      "    :param random_state: ignored, added for uniformity.\n",
      "    :param dict kwargs: additional arguments to net __init__, varies with different net_types\n",
      "\n",
      "    .. seealso:: https://pythonhosted.org/neurolab/lib.html for supported train functions and their parameters.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import NeurolabClassifier\n",
    "print NeurolabClassifier.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of train epochs is reached\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "import neurolab \n",
    "nl = NeurolabClassifier(features=variables, layers=[10], epochs=20, trainf=neurolab.train.train_rprop)\n",
    "nl.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities and estimate quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21881075  0.78118925]\n",
      " [ 0.18726815  0.81273185]\n",
      " [ 0.20386355  0.79613645]\n",
      " ..., \n",
      " [ 0.21367134  0.78632866]\n",
      " [ 0.18782973  0.81217027]\n",
      " [ 0.20105149  0.79894851]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = nl.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.82096289122\n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict labels\n",
    "nl.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pybrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implements classification from PyBrain library \n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    :param features: features used in training.\n",
      "    :type features: list[str] or None\n",
      "    :param scaler: transformer to apply to the input objects\n",
      "    :type scaler: str or sklearn-like transformer or False (do not scale features)\n",
      "    :param bool use_rprop: flag to indicate whether we should use Rprop or SGD trainer\n",
      "    :param bool verbose: print train/validation errors.\n",
      "    :param random_state: ignored parameter, pybrain training isn't reproducible\n",
      "\n",
      "    **Net parameters:**\n",
      "\n",
      "    :param list[int] layers: indicate how many neurons in each hidden(!) layer; default is 1 hidden layer with 10 neurons\n",
      "    :param list[str] hiddenclass: classes of the hidden layers; default is 'SigmoidLayer'\n",
      "    :param dict params: other net parameters:\n",
      "        bias and outputbias (boolean) flags to indicate whether the network should have the corresponding biases,\n",
      "        both default to True;\n",
      "        peepholes (boolean);\n",
      "        recurrent (boolean) if the `recurrent` flag is set, a :class:`RecurrentNetwork` will be created,\n",
      "        otherwise a :class:`FeedForwardNetwork`\n",
      "\n",
      "    **Gradient descent trainer parameters:**\n",
      "\n",
      "    :param float learningrate: gives the ratio of which parameters are changed into the direction of the gradient\n",
      "    :param float lrdecay: the learning rate decreases by lrdecay, which is used to multiply the learning rate after each training step\n",
      "    :param float momentum: the ratio by which the gradient of the last timestep is used\n",
      "    :param boolean batchlearning: if set, the parameters are updated only at the end of each epoch. Default is False\n",
      "    :param float weightdecay: corresponds to the weightdecay rate, where 0 is no weight decay at all\n",
      "\n",
      "    **Rprop trainer parameters:**\n",
      "\n",
      "    :param float etaminus: factor by which step width is decreased when overstepping (0.5)\n",
      "    :param float etaplus: factor by which step width is increased when following gradient (1.2)\n",
      "    :param float delta: step width for each weight\n",
      "    :param float deltamin: minimum step width (1e-6)\n",
      "    :param float deltamax: maximum step width (5.0)\n",
      "    :param float delta0: initial step width (0.1)\n",
      "\n",
      "    **Training termination parameters**\n",
      "\n",
      "    :param int epochs: number of iterations of training; if < 0 then classifier trains until convergence\n",
      "    :param int max_epochs: if is given, at most that many epochs are trained\n",
      "    :param int continue_epochs: each time validation error decreases, try for continue_epochs epochs to find a better one\n",
      "    :param float validation_proportion: the ratio of the dataset that is used for the validation dataset\n",
      "\n",
      "    .. note::\n",
      "\n",
      "        Details about parameters: http://pybrain.org/docs/\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import PyBrainClassifier\n",
    "print PyBrainClassifier.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "pb = PyBrainClassifier(features=variables, epochs=2, layers=[10, 2], hiddenclass=['LinearLayer', 'MDLSTMLayer'])\n",
    "pb.fit(train_data, train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities and estimate quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.900121016332\n"
     ]
    }
   ],
   "source": [
    "prob = pb.predict_proba(test_data)\n",
    "print 'ROC AUC:', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages of common interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show that now you can run AdaBoost over neural nets! <br />\n",
    "_(isn't boosting over neural network what you were dreaming of all your life?)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging over Theanets classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_tn = TheanetsClassifier(trainers=[{'min_improvement': 0.1}])\n",
    "bagging_tn = BaggingClassifier(base_estimator=base_tn, n_estimators=3)\n",
    "bagging_tn.fit(train_data[variables], train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.901499256418\n"
     ]
    }
   ],
   "source": [
    "prob = bagging_tn.predict_proba(test_data[variables])\n",
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging over Neurolab classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of train epochs is reached\n",
      "The maximum number of train epochs is reached\n",
      "The maximum number of train epochs is reached\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "base_nl = NeurolabClassifier(layers=[10], epochs=20, trainf=neurolab.train.train_rprop)\n",
    "bagging_nl = BaggingClassifier(base_estimator=base_nl, n_estimators=3)\n",
    "bagging_nl.fit(train_data[variables], train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.807962872474\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = bagging_nl.predict_proba(test_data[variables])\n",
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging over Pybrain classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "base_pb = PyBrainClassifier(epochs=2, layers=[10, 2], hiddenclass=['LinearLayer', 'MDLSTMLayer'])\n",
    "bagging_pb = BaggingClassifier(base_estimator=base_pb, n_estimators=3)\n",
    "bagging_pb.fit(train_data[variables], train_labels)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.903090297511\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each class\n",
    "prob = bagging_pb.predict_proba(test_data[variables])\n",
    "print 'AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other advantages of common interface\n",
    "There are many things you can do with classifiers now: \n",
    "* cloning\n",
    "* getting / setting parameters as dictionaries \n",
    "* do automatic hyperparameter optimization \n",
    "* build pipelines (`sklearn.pipeline`)\n",
    "* use hierarchical training, training on subsets\n",
    "* passing over internet / train classifiers on other machines\n",
    "\n",
    "And you can replace classifiers at any moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1. Play with parameters in each type of classifiers\n",
    "\n",
    "### Exercise 2. Play with `partial_fit` for different models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
